README
------

This software reads an English Wikipedia dump and outputs a cooccurrence graph in terms of edges. There are several ways to acheive this.

The Really Easy Way
-------------------

1. $ mkdir -p /some/dir/to/store/the/output
2. $ perl wiki_bz_to_cooc.pl /absolute/path/to/wiki-latest.bz2 /some/dir/to/store/the/output
3. The output will be in /some/dir/to/store/the/output/cooccurrence_edges

Note 1: This will run for around 20hrs and temporarily uses around 200GB of space for 6GB wikidump.
Note 2: Depends on Perl and *nix programs -- bzcat, awk, sed. Doesn't depend on any non-standard perl libraries

For Hadoop/Map-Reduce Usage
---------------------------

1. Run this on a regular machine before moving into a Hadoop environment. 
    $ bzcat /path/to/enwiki-latest-pages-articles.xml.bz2 | ./clean.pl > wiki_articles_as_lines
2. Assign this command to the mapper: 
    `cat wiki_articles_as_lines | ./keywords.pl | ./cooccurrence.pl`. It emits tab seperated word pairs.
3. Collect and count the word pairs in a reducer/combiner.

For Custom Usage
----------------

1. Covert the bzipped xml dump into one article per line mode.
    $ bzcat /path/to/enwiki-latest-pages-articles.xml.bz2 | ./clean.pl > wiki_articles_as_lines
2. Open keywords.pl and set the required options at the top.
3. Extract keywords from each section of an article: 
    $ cat wiki_articles_as_lines | ./keywords.pl > keywords
4. Convert them to cooccurrences: 
    $ cat keywords > ./cooccurrence.pl > cooccurrences
5. To count the cooccurrences and format them
    $ cat cooccurrences | sort | uniq -c | sed 's/^\s*//' | sed 's/\s/\t/' | awk -F \\t 'BEGIN{OFS="\\t"}{print $2,$3,$1}' > coocurrence_edges


For Batch Processing
--------------------
1. Follow steps 1 and 2 from above. After step 2, run 
    $ cat wiki_articles_as_lines | ./batch/splitter.pl /path/to/splits/dir 10000
    Note: 10000 was the split size    
2. Put as many of those splits as you want into a dir and run 
    $ ./batch/process.pl /path/to/splits/dir /path/to/coocs/dir
3. To consolidate the cooccurrences in different splits, run
    $ sort -T /path/to/a/temp/sorted/dir -m /path/to/coocs/dir/* > /path/to/a/temp/sorted/cooccurrences
4. Run step 5 from the above method.

